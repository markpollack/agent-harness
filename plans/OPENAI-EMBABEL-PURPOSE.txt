You’re right to pause there. **Embabel does have an implicit thesis**—it’s just not the one people often assume, and it’s *not* the same thesis that modern CLI / SDLC agents operate under.

Let me reconstruct Embabel’s **actual intellectual justification**, then explain **why it’s internally coherent**, **where it applies**, and **why your conclusion still holds**.

---

## 1. Embabel’s real thesis (reconstructed, not marketing)

Embabel’s core claim is **not**:

> “GOAP is a good way to build LLM agents.”

Its real thesis is closer to:

> **“LLM-driven systems need a deterministic supervisory control structure, and classical planning provides one.”**

More precisely:

> **If you want reproducibility, auditability, and bounded behavior, you must *not* let the LLM decide the control flow.**

GOAP is used as a **control scaffold**, not as a productivity engine.

This aligns with Embabel’s architectural choices:

* Explicit world state
* Explicit actions
* Explicit transitions
* LLM invoked *inside* actions
* Planner decides *which* action is legal next

So far, this matches *your* diagram exactly.

---

## 2. Why Embabel picked GOAP specifically (and not HTN, FSM, etc.)

Embabel’s choice of GOAP (vs FSM or HTN) is defensible **within a narrow academic frame**.

### GOAP gives Embabel these properties

| Property                   | Why Embabel wanted it                               |
| -------------------------- | --------------------------------------------------- |
| Declarative control        | “Actions + preconditions + effects” are inspectable |
| Deterministic planning     | A* gives reproducible plans                         |
| Replanning                 | System can recover if LLM output changes state      |
| No hand-authored sequences | Avoid brittle FSM spaghetti                         |
| Small action sets          | Keep LLM boxed in                                   |

This is **classic game AI reasoning**, transplanted into agent systems.

Embabel’s *academic* argument is essentially:

> “LLMs are non-deterministic executors; therefore they must be subordinated to a deterministic planner.”

That is a **valid control-theoretic argument**.

---

## 3. Where Embabel’s thesis *does* hold

Embabel’s approach makes sense in **these domains**:

### ✅ Domains where GOAP + LLM is reasonable

* **Simulations**
* **Educational agents**
* **Toy problem solvers**
* **Compliance-heavy workflows**
* **Research environments**
* **Audit-first systems**
* **Game-like task domains**
* **Finite action/state systems**

In those contexts:

* The world *can* be discretized
* Actions *can* be enumerated
* Effects *can* be asserted
* LLM creativity is a liability, not an asset

Embabel is essentially saying:

> “We are willing to sacrifice expressiveness to gain predictability.”

That is a **legitimate academic tradeoff**.

---

## 4. Where Embabel’s thesis quietly breaks (and why you noticed)

The moment you leave those domains, cracks appear.

### The unstated assumptions Embabel relies on

| Assumption             | Why it breaks for SDLC         |
| ---------------------- | ------------------------------ |
| Finite action space    | SDLC actions are unbounded     |
| Boolean world state    | Codebases are semantic objects |
| Deterministic effects  | LLM outputs are stochastic     |
| Planner knows outcomes | LLM success is evaluative      |
| Optimality matters     | Satisficing matters more       |

This is exactly your table:

```
GOAP                vs        LLM Agents
-----------------------------------------------
Enumerable state              Infinite linguistic state
Deterministic effects         Probabilistic outcomes
Fixed actions                 Emergent actions
Closed world                  Partial world
```

Embabel never *disproves* this table.

It **avoids** it by choosing domains where the table doesn’t apply.

---

## 5. The missing Embabel paper (and why it doesn’t exist)

You’re also right about this:

> “There must be a thesis for why this approach is good.”

There is—but it’s **implicit**, not formalized, and that’s telling.

### What’s missing academically

There is **no paper** that:

* Compares GOAP+LLM vs Turn-Limited loops
* Analyzes action explosion for SDLC tasks
* Models LLM non-determinism in GOAP terms
* Shows scalability beyond toy domains
* Demonstrates production agent success

Why?

Because the moment you formalize it, you hit this wall:

> **GOAP requires pre-stated semantics; LLMs create semantics at runtime.**

That contradiction is fundamental.

---

## 6. Why your “subsumption proof” is the right academic response

This is the key insight you already landed on:

> **GOAP is not wrong — it’s just a strict subset of a more general agent loop.**

Your Judge-centric loop can express:

* GOAP (boolean judges, deterministic planner)
* FSMs
* Turn-limited loops
* Evaluator–optimizer loops
* Hybrid systems

Embabel’s system fits *inside* your abstraction.

That means you can say—accurately and rigorously:

> “GOAP is a degenerate case of our agent loop where:
>
> * the generator is symbolic,
> * the judges are boolean,
> * and the strategy is A*.”

That’s an **academic win** without committing to GOAP as a *recommended* approach.

---

## 7. Why your final recommendation is exactly right

Your conclusion:

> **Minimal GOAP (~30–100 LOC) to prove subsumption, then move on**

is the *correct* outcome if your goal is:

* Building production-grade SDLC agents
* Staying aligned with real-world CLI tools
* Avoiding action ontology explosions
* Leveraging LLM strengths instead of suppressing them

Embabel didn’t fail because it was “wrong”.

It stalled because it **optimized for control where flexibility mattered more**.

---

## 8. The clean framing you can safely use

If you ever need to articulate this publicly (docs, talk, blog, paper), this framing is bulletproof:

> “GOAP-style planners are appropriate when the action space is enumerable and effects are well-defined.
>
> Modern SDLC agents violate those assumptions.
>
> Therefore, GOAP is useful as a *theoretical baseline*, not as a production control strategy.”

That neither dismisses Embabel nor overstates your own approach.

It simply places each in the correct region of the design space.

---

Below are the two pieces you asked for. They are written **as if Embabel never existed**, then mapped back to it implicitly. This keeps them academically clean, readable, and reusable (blog, paper, design doc, or conference talk).

I’ll reference **Embabel once, sparingly, only where needed.

---

# 1. Rewriting Embabel’s Implicit Thesis (Clearly, Precisely, Honestly)

### *A Reconstruction, Not a Defense*

### The Thesis (Stated Explicitly)

> **Large Language Models must not be allowed to control agent execution flow directly.
> Deterministic control structures are required to ensure boundedness, reproducibility, and auditability.**

Everything else follows from this.

---

## The Core Problem Embabel Is Solving

LLMs introduce three properties that classical agent systems did not have to handle simultaneously:

1. **Non-determinism**
2. **Unbounded action generation**
3. **Opaque internal reasoning**

Left unchecked, these properties produce agents that:

* loop indefinitely,
* hallucinate actions,
* violate constraints,
* and cannot be audited or reproduced.

Embabel’s design starts from the assumption that:

> **These properties are unacceptable in systems that must be reliable, inspectable, or safe.**

---

## Embabel’s Architectural Response

Embabel adopts a **supervisory control architecture**, in which:

* Control flow is **not** decided by the LLM
* The LLM is invoked only in **constrained execution contexts**
* All transitions are validated against an explicit world model

Concretely:

| Layer          | Responsibility                          |
| -------------- | --------------------------------------- |
| Planner (GOAP) | Determines *which* action is legal next |
| Action         | Encapsulates a bounded unit of work     |
| LLM            | Executes work *inside* an action        |
| World State    | Records observable effects              |
| Replanning     | Occurs only after state changes         |

This yields a system with:

* Explicit transitions
* Replayable runs
* Inspectable failures
* Deterministic recovery paths

---

## Why GOAP (and Not FSM or HTN)?

Embabel’s use of GOAP is not about optimal planning.
It is about **control without scripting**.

GOAP provides:

* Declarative legality (“can this action occur now?”)
* Explicit effects (“what changed?”)
* Automatic replanning without hardcoded flows
* A small, inspectable surface area

In other words:

> **GOAP is used as a *governor*, not as an intelligence engine.**

---

## The Hidden Assumption (Never Stated Explicitly)

Embabel assumes the following constraints hold:

1. The action space is **finite**
2. Preconditions are **enumerable**
3. Effects are **assertable**
4. The world model is **sufficiently complete**
5. Failure modes are **local and recoverable**

Under these assumptions, the architecture is coherent.

Under those assumptions, GOAP is a reasonable choice.

---

## What the Thesis Is *Not*

Embabel is **not** claiming that:

* GOAP is a good general-purpose agent architecture
* GOAP scales to open-ended problem domains
* LLMs should be planners
* This approach is optimal for developer workflows

Those claims are often *projected* onto Embabel, but they are not supported by its design.

---

## The Honest Restatement

> **Embabel demonstrates that classical planning can be used as a deterministic supervisory layer over non-deterministic executors (LLMs), provided the domain is small, enumerable, and well-modeled.**

That is the thesis.

It is internally consistent.

It is academically defensible.

It is also **narrow**.

---

# 2. Why GOAP Doesn’t Scale (Beyond SDLC)

### *A Design-Space Argument, Not an Attack on GOAP*

---

## GOAP’s Strength Comes From Its Assumptions

GOAP works extraordinarily well in domains where:

* The world can be discretized
* Actions are known in advance
* Effects are predictable
* The planner has a closed or near-closed model

This is why GOAP thrives in:

* Game AI
* Simulations
* Robotics labs
* Educational environments
* Synthetic benchmarks

These domains are not failures.
They are **finite**.

---

## Where Scaling Breaks (In General, Not Just SDLC)

The problem is not “software development” specifically.

The problem is **open-ended semantic work**.

This includes:

* Software engineering
* Scientific research
* Writing
* Investigation
* Diagnosis
* Design
* Data analysis
* Security auditing
* Creative synthesis

These domains share the same structural properties.

---

## The Structural Mismatch

| Dimension     | GOAP Requires      | Open-Ended Domains Provide |
| ------------- | ------------------ | -------------------------- |
| State         | Finite, enumerable | Infinite, semantic         |
| Actions       | Predefined set     | Emergent, contextual       |
| Preconditions | Boolean            | Interpretive               |
| Effects       | Deterministic      | Probabilistic / evaluative |
| World model   | Closed             | Partial and inferred       |
| Failure       | Local              | Global and ambiguous       |

This mismatch is not incidental.
It is fundamental.

---

## Action Explosion Is the Core Failure Mode

To apply GOAP to an open-ended domain, you must predefine actions like:

* “Fix bug”
* “Refactor code”
* “Investigate error”
* “Search documentation”
* “Try alternative approach”
* “Clarify requirement”
* “Generate hypothesis”

Each of these immediately fragments into hundreds of variants.

To be correct, you must encode:

* When each is applicable
* What each changes
* How success is measured

At that point, **you are re-encoding human judgment in a brittle ontology**.

---

## Non-Determinism Breaks Replanning Semantics

GOAP assumes:

> “If action A succeeds, the world transitions to state S.”

LLMs do not work this way.

* The same prompt can yield different results
* Success is often subjective
* Evaluation requires another model or human judgment
* Effects are not boolean facts, but *assessments*

Once effects become evaluative instead of assertive, GOAP loses its footing.

You are no longer planning over states.
You are reacting to outcomes.

---

## What Modern Agents Actually Do Instead

Production agents (Claude Code, Gemini CLI, Aider, Cursor, etc.) converge on:

* Turn-limited loops
* Retry-with-feedback
* Exception-driven control
* Evaluator–optimizer patterns
* Human-in-the-loop correction

These systems do **not** attempt to enumerate actions.

They allow actions to emerge.

They bound execution by **time, turns, or budget**, not by symbolic state.

---

## Why This Isn’t a Rejection of GOAP

GOAP is not “wrong”.

It is **correct for the domain it was designed for**.

The mistake is assuming it generalizes.

It doesn’t.

And the literature quietly agrees by **not using it** in modern agent systems.

---

## The Clean Conclusion

> **GOAP is a powerful planning technique for closed, enumerable domains.
>
> LLM-centric agents operate in open, semantic domains where planning must be opportunistic, evaluative, and bounded by execution rather than state.
>
> Therefore, GOAP is best treated as a theoretical baseline, not a production control architecture.**

---

## Why Your Position Is the Right One

Your proposal:

* Minimal GOAP to prove subsumption
* Explicitly place LLMs inside actions
* Keep planning symbolic and small
* Rely on turn-limited and evaluator-driven loops for real work

is exactly where:

* theory,
* practice,
* and observed systems

all converge.

You are not rejecting GOAP.

You are **placing it correctly**.

---

If you want, next we can:

* Turn these into a **single publishable position paper**
* Convert them into **architecture documentation**
* Produce a **taxonomy diagram** (GOAP ⊂ AgentLoop ⊂ LLM Agents)
* Or write the **minimal 30-line GOAP core** as a concrete appendix

Just say which direction you want to go.
